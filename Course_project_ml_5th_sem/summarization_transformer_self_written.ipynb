{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('data\\\\news.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "      <th>Source</th>\n",
       "      <th>Time</th>\n",
       "      <th>Publish Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "      <td>The New Indian Express</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>2017-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "      <td>Outlook</td>\n",
       "      <td>22:18:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "      <td>Hindustan Times</td>\n",
       "      <td>23:39:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>23:08:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>23:24:00</td>\n",
       "      <td>2017-03-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short                 Source   \\\n",
       "0  The CBI on Saturday booked four former officia...  The New Indian Express   \n",
       "1  Chief Justice JS Khehar has said the Supreme C...                 Outlook   \n",
       "2  At least three people were killed, including a...         Hindustan Times   \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...                Livemint   \n",
       "4  TV news anchor Arnab Goswami has said he was t...                 YouTube   \n",
       "\n",
       "      Time  Publish Date  \n",
       "0  09:25:00   2017-03-26  \n",
       "1  22:18:00   2017-03-25  \n",
       "2  23:39:00   2017-03-25  \n",
       "3  23:08:00   2017-03-25  \n",
       "4  23:24:00   2017-03-25  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI on Saturday booked four former officia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>At least three people were killed, including a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  \\\n",
       "0  4 ex-bank officials booked for cheating bank o...   \n",
       "1     Supreme Court to go paperless in 6 months: CJI   \n",
       "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3  Why has Reliance been barred from trading in f...   \n",
       "4  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                               Short  \n",
       "0  The CBI on Saturday booked four former officia...  \n",
       "1  Chief Justice JS Khehar has said the Supreme C...  \n",
       "2  At least three people were killed, including a...  \n",
       "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
       "4  TV news anchor Arnab Goswami has said he was t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['Headline','Short']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55104, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        The CBI on Saturday booked four former officia...\n",
       "1        Chief Justice JS Khehar has said the Supreme C...\n",
       "2        At least three people were killed, including a...\n",
       "3        Mukesh Ambani-led Reliance Industries (RIL) wa...\n",
       "4        TV news anchor Arnab Goswami has said he was t...\n",
       "                               ...                        \n",
       "55099    Tracking weak cues from the Asian markets, the...\n",
       "55100    Amid growing concerns about China&#39;s econom...\n",
       "55101    Pakistani Ghazal singer Ghulam Ali will soon m...\n",
       "55102    The Islamic State (IS) has acknowledged the de...\n",
       "55103    UK-based oil firm Cairn Energy on Tuesday said...\n",
       "Name: Short, Length: 55104, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df['Short']\n",
    "summary=df['Headline']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <start>4 ex-bank officials booked for cheating...\n",
       "1    <start>Supreme Court to go paperless in 6 mont...\n",
       "2    <start>At least 3 killed, 30 injured in blast ...\n",
       "3    <start>Why has Reliance been barred from tradi...\n",
       "4    <start>Was stopped from entering my own studio...\n",
       "Name: Headline, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary=summary.apply(lambda x:'<start>' + x + '<stop>')\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start>4 ex-bank officials booked for cheating bank of â‚¹209 crore<stop>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1153, 9, 116, 1912, 152, 109, 171, 6, 11881, 180, 8, 209, 326, 12, 3907, 17737, 1467, 3712, 8, 1913, 28258, 55, 735, 3, 2, 61, 295, 180, 2, 236, 35, 11882, 242, 1626, 8, 1809, 20, 11881, 180, 9, 2, 1452, 6, 7463, 8, 13762, 1504, 293, 863, 39, 17738, 3738, 3, 2, 458, 914, 17, 2, 236, 1712]\n",
      "[565, 199, 146, 968, 605, 6, 2518, 146, 7, 17635, 234]\n"
     ]
    }
   ],
   "source": [
    "doc_tokenizer=Tokenizer(oov_token='<oov>')\n",
    "doc_tokenizer.fit_on_texts(text)\n",
    "text_tokens=doc_tokenizer.texts_to_sequences(text)\n",
    "print(text_tokens[0])\n",
    "summary_tokenizer=Tokenizer(filters=filters,oov_token='<oov>')\n",
    "summary_tokenizer.fit_on_texts(summary)\n",
    "summary_tokens=summary_tokenizer.texts_to_sequences(summary)\n",
    "print(summary_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=text_tokens\n",
    "targets=summary_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76362, 44069)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_vocab_size = len(doc_tokenizer.word_index) + 1\n",
    "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
    "encoder_vocab_size, decoder_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "97\n"
     ]
    }
   ],
   "source": [
    "document_lengths = pd.Series([len(x) for x in text])\n",
    "summary_lengths=pd.Series([len(x) for x in summary])\n",
    "print(document_lengths.max())\n",
    "print(summary_lengths.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    55104.000000\n",
      "mean       368.003049\n",
      "std         26.235510\n",
      "min        280.000000\n",
      "25%        350.000000\n",
      "50%        369.000000\n",
      "75%        387.000000\n",
      "max        469.000000\n",
      "dtype: float64\n",
      "count    55104.000000\n",
      "mean        64.620282\n",
      "std          7.267463\n",
      "min         21.000000\n",
      "25%         60.000000\n",
      "50%         64.000000\n",
      "75%         70.000000\n",
      "max         97.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(document_lengths.describe())\n",
    "print(summary_lengths.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469, 97)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_maxlen=document_lengths.max()\n",
    "decoder_maxlen=summary_lengths.max()\n",
    "encoder_maxlen,decoder_maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size=20000\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos,i,d_model): # pos - max_sequence\n",
    "    d_model=6\n",
    "    pos=10\n",
    "    i = tf.range(0, d_model, 2, dtype=tf.float32)\n",
    "    denominator = tf.pow(10000, i / d_model)\n",
    "    pos = tf.expand_dims(tf.range(pos, dtype=tf.float32), axis=1)\n",
    "    even_PE = tf.sin(pos / denominator)\n",
    "    # even_PE.shape\n",
    "    odd_PE = tf.cos(pos / denominator)\n",
    "    # odd_PE\n",
    "    stacked = tf.stack([even_PE, odd_PE], axis=2)\n",
    "    PE = tf.reshape(stacked, shape=(-1, d_model))\n",
    "    return PE\n",
    "# # Testing the function\n",
    "# # result = positional_encoding(10, 0, 6)\n",
    "# print(result.shape)\n",
    "# print(result)\n",
    "# positional_encoding(10,0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q,k,v,mask):\n",
    "    matmul_qk=tf.matmul(q,k,transpose_b=True)  #perform q.kT\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)  #size of k in float\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) #axis=-1 for last dimension\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "#     def __init__(self,d_model,num_heads):\n",
    "#         super(MultiHeadAttention).__init__() #class inherited using super function\n",
    "#         self.d_model=d_model\n",
    "#         self.num_heads=num_heads\n",
    "#         assert d_model % num_heads\n",
    "#         self.depth=d_model//num_heads\n",
    "#         #create layers for query key and value\n",
    "#         self.wq=tf.keras.layers.Dense(d_model) #query\n",
    "#         self.wk=tf.keras.layers.Dense(d_model) #key\n",
    "#         self.wv=tf.keras.layers.Dense(d_model) #value\n",
    "#         self.dense=tf.keras.layers.Dense(d_model)  #output layer\n",
    "#     def split_heads(self,x,batch_size):\n",
    "#         self.x=tf.reshape(x,(batch_size,-1,self.num_heads,self.depth))#-1 such that size remains constant\n",
    "#         return tf.transpose(x,perm=[0,2,1,3])\n",
    "#     def call(self,v,k,q,mask):\n",
    "#         q=self.wq(q)\n",
    "#         k=self.wk(k)\n",
    "#         v=self.wv(v)\n",
    "#         q=self.split_heads(q,batch_size)\n",
    "#         k=self.split_heads(k,batch_size)\n",
    "#         v=self.split_heads(v,batch_size)\n",
    "#         scaled_attention , attention_weights= scaled_dot_product(q,k,v,mask)\n",
    "#         scaled_attention=tf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(x):\n",
    "        super(Encoder,self).__init__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
